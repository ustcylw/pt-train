{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test yolo-v5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath('.'))))\n",
    "sys.path.append(os.path.dirname(os.path.abspath('.')))\n",
    "import pl_yolo_v5.src.dataset.dataset as Data\n",
    "from imp import reload\n",
    "reload(Data)\n",
    "\n",
    "os.system(f'rm /data/ylw/code/yolo/yolov5-pytorch/test/test_rets/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from src.utils.voc_utils import get_anchors\n",
    "from PyUtils.logs.print import *\n",
    "from PyUtils.viz.plot_draw import heatmap\n",
    "from src.dataset.dataset import YoloDataset\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "train_annotation_path = '../data/2007_train.txt'\n",
    "with open(train_annotation_path, encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "lines = lines[:120]\n",
    "\n",
    "input_shape     = [640, 640]\n",
    "num_classes = 20\n",
    "anchors_path    = '../model_data/yolo_anchors.txt'\n",
    "anchors, num_anchors     = get_anchors(anchors_path)\n",
    "UnFreeze_Epoch      = 300\n",
    "batch_size = 8\n",
    "num_workers = 1\n",
    "anchors_mask    = [[6, 7, 8], [3, 4, 5], [0, 1, 2]]\n",
    "mosaic              = True\n",
    "mosaic_prob         = 0.5\n",
    "mixup               = True\n",
    "mixup_prob          = 0.5\n",
    "\n",
    "test_dataset   = YoloDataset(\n",
    "    lines, \n",
    "    input_shape, \n",
    "    num_classes, \n",
    "    anchors, \n",
    "    anchors_mask, \n",
    "    mosaic=mosaic, \n",
    "    mixup=mixup, \n",
    "    mosaic_prob=mosaic_prob, \n",
    "    mixup_prob=mixup_prob, \n",
    "    train=True, \n",
    ")\n",
    "loader = DataLoader(\n",
    "    test_dataset, \n",
    "    shuffle = False, \n",
    "    batch_size = batch_size, \n",
    "    num_workers = num_workers, \n",
    "    pin_memory=True,\n",
    "    drop_last=True, \n",
    "    collate_fn=test_dataset.yolo_dataset_collate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, batch in enumerate(loader):\n",
    "    sllog << f'[============][{batch_idx}]  {batch[0].shape=}  {len(batch[1])=} / {type(batch[1][0])=} / {batch[1][0].shape=}  {batch[2][0].shape=}  {batch[2][1].shape=}  {batch[2][2].shape=}'\n",
    "\n",
    "    images = batch[0]\n",
    "    for idx, image in enumerate(images):\n",
    "        img = (image.numpy().transpose((1,2,0))*255).astype(np.uint8)\n",
    "        img = cv2.UMat(img)\n",
    "        \n",
    "        for box in batch[1][idx].numpy():\n",
    "            input_shape = img.get().shape[1]\n",
    "            if len(box.shape) == 1:\n",
    "                box = box[np.newaxis, :]\n",
    "            bbox = box[:, :4] * input_shape\n",
    "            cls = box[:, 4]\n",
    "            for b in bbox:\n",
    "                img = cv2.rectangle(\n",
    "                    cv2.UMat(img), \n",
    "                    (int(b[0]-b[2]/2), int(b[1]-b[3]/2)), (int(b[0]+b[2]/2), int(b[1]+b[3]/2)), \n",
    "                    color=(0, 0, 255), thickness=2\n",
    "                )\n",
    "\n",
    "        iw_ret = cv2.imwrite(f'/data/ylw/code/pl_yolo_v5/test/rets2/{batch_idx}-{idx}.jpg', img)\n",
    "        \n",
    "    if (batch_idx+1) % 2 == 0:\n",
    "        break;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, batch in enumerate(loader):\n",
    "    sllog << f'[============][{batch_idx}]  {batch[0].shape=}  {len(batch[1])=} / {batch[1][0].shape=}  {batch[2][0].shape=}  {batch[2][1].shape=}  {batch[2][2].shape=}'\n",
    "\n",
    "    images = batch[0]\n",
    "    for idx, image in enumerate(images):\n",
    "        img = (image.numpy().transpose((1,2,0))*255).astype(np.uint8)\n",
    "        # img = cv2.UMat(img)\n",
    "        input_shape = img.shape[1]\n",
    "        \n",
    "        data1 = batch[2][0][idx, :, :, :, :].numpy().sum(axis=3).transpose((1,2,0))\n",
    "        data2 = batch[2][1][idx, :, :, :, :].numpy().sum(axis=3).transpose((1,2,0))\n",
    "        data3 = batch[2][2][idx, :, :, :, :].numpy().sum(axis=3).transpose((1,2,0))\n",
    "        sllog << f'{data1.shape=}  {data2.shape=}  {data3.shape=}'\n",
    "        data1 = cv2.resize(data1, (input_shape, input_shape))\n",
    "        data2 = cv2.resize(data2, (input_shape, input_shape))\n",
    "        data3 = cv2.resize(data3, (input_shape, input_shape))\n",
    "        data = (data1 + data2 + data3).astype(np.uint8)\n",
    "        \n",
    "        # fig, ax = heatmap(data, save_file=f'/data/ylw/code/pl_yolo_v5/test/rets3/{batch_idx}-{idx}-hm.jpg', show=False)\n",
    "        \n",
    "        for box in batch[1][idx].numpy():\n",
    "            if len(box.shape) == 1:\n",
    "                box = box[np.newaxis, :]\n",
    "            bbox = box[:, :4] * input_shape\n",
    "            cls = box[:, 4]\n",
    "            for b in bbox:\n",
    "                img = cv2.rectangle(\n",
    "                    cv2.UMat(img), \n",
    "                    (int(b[0]-b[2]/2), int(b[1]-b[3]/2)), (int(b[0]+b[2]/2), int(b[1]+b[3]/2)), \n",
    "                    color=(0, 0, 255), thickness=2\n",
    "                )\n",
    "\n",
    "        # iw_ret = cv2.imwrite(f'/data/ylw/code/pl_yolo_v5/test/rets3/{batch_idx}-{idx}-1.jpg', data1)\n",
    "        # iw_ret = cv2.imwrite(f'/data/ylw/code/pl_yolo_v5/test/rets3/{batch_idx}-{idx}-2.jpg', data2)\n",
    "        # iw_ret = cv2.imwrite(f'/data/ylw/code/pl_yolo_v5/test/rets3/{batch_idx}-{idx}-3.jpg', data3)\n",
    "        # iw_ret = cv2.imwrite(f'/data/ylw/code/pl_yolo_v5/test/rets3/{batch_idx}-{idx}.jpg', data)\n",
    "        img = cv2.addWeighted(cv2.UMat(img), 0.5, data, 0.8, 1)\n",
    "        iw_ret = cv2.imwrite(f'/data/ylw/code/pl_yolo_v5/test/rets3/{batch_idx}-{idx}.jpg', img)\n",
    "    \n",
    "    if (batch_idx+1) % 2 == 0:\n",
    "        break;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyUtils.viz.plot_draw as draw\n",
    "import numpy as np\n",
    "a = np.linspace(0,99, 100).reshape((10, 10))\n",
    "draw.heatmap(a, save_file='./hello.png', show=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath('.'))))\n",
    "from src.nets.yolo import YoloBody\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi             = 's'\n",
    "backbone        = 'cspdarknet'\n",
    "num_classes = 20\n",
    "anchors_path    = '../model_data/yolo_anchors.txt'\n",
    "anchors, num_anchors     = get_anchors(anchors_path)\n",
    "anchors_mask    = [[6, 7, 8], [3, 4, 5], [0, 1, 2]]\n",
    "input_shape     = [640, 640]\n",
    "pretrained      = False\n",
    "\n",
    "model = YoloBody(anchors_mask, num_classes, phi, backbone, pretrained=pretrained, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_scales = [320, 416, 640, 1024]  # [32, 16, 8]\n",
    "for scale in multi_scales:\n",
    "    input_data = torch.rand(size=(1, 3, scale, scale))\n",
    "    preds = model(input_data)\n",
    "    print(f'{preds[0].shape=}  {preds[1].shape=}  {preds[2].shape=}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.loss.yolov5_loss as YoloLoss\n",
    "reload(YoloLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 4\n",
    "batch_size = 4\n",
    "\n",
    "test_dataset   = YoloDataset(\n",
    "    lines, \n",
    "    input_shape, \n",
    "    num_classes, \n",
    "    anchors, \n",
    "    anchors_mask, \n",
    "    mosaic=mosaic, \n",
    "    mixup=mixup, \n",
    "    mosaic_prob=mosaic_prob, \n",
    "    mixup_prob=mixup_prob, \n",
    "    train=True, \n",
    "    fixed_input_shape=True\n",
    ")\n",
    "loader = DataLoader(\n",
    "    test_dataset, \n",
    "    shuffle = False, \n",
    "    batch_size = batch_size, \n",
    "    num_workers = num_workers, \n",
    "    pin_memory=True,\n",
    "    drop_last=True, \n",
    "    collate_fn=test_dataset.yolo_dataset_collate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_smoothing = 0\n",
    "Cuda = False\n",
    "\n",
    "Loss = YoloLoss.YOLOLoss(\n",
    "    anchors, \n",
    "    num_classes, \n",
    "    input_shape, \n",
    "    anchors_mask, \n",
    "    label_smoothing\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    # 一个epoch内无法修改dataloader中input的尺寸\n",
    "    for batch_idx, batch in enumerate(loader):\n",
    "        data, bboxes, gts = batch\n",
    "        sllog << f'[************][{i}][{batch_idx}]  {data.shape=}  {len(bboxes)=}  {gts[0].shape=}  {gts[1].shape=}  {gts[2].shape=}'\n",
    "        preds = model(data)\n",
    "        sllog << f'[{i}][{batch_idx}]  {preds[0].shape=}  {preds[1].shape=}  {preds[2].shape=}  {test_dataset.input_shape=}  {loader.dataset.input_shape=}'\n",
    "\n",
    "        loss = 0\n",
    "        with torch.no_grad():\n",
    "            for idx, pred in enumerate(preds):\n",
    "                loss += Loss(idx, pred, bboxes, gts[idx], batch)\n",
    "        sllog << f'[{i}][{batch_idx}]  {loss.item()=}'\n",
    "        \n",
    "        input_scale = np.array([160, 160]) * (batch_idx+1)\n",
    "        sllog << f'[============][{i}][{batch_idx}]  set input shape {input_scale}  {id(test_dataset)}  {id(loader)}  {id(test_dataset.input_shape)}  ...'\n",
    "        # loader.dataset.input_shape = input_scale\n",
    "        test_dataset.set_input_shape(160 * (batch_idx+1))\n",
    "        sllog << f'='*80\n",
    "        if (batch_idx+1) % 3 == 0:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "16 / 8 * 2 / 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from turtle import shape\n",
    "import numpy as np\n",
    "\n",
    "a = np.array([[1,2,3,4], [5,6,7,8]])\n",
    "b = np.array([[1,3,5,7]])\n",
    "print(f'{a.shape=}  {b.shape=}')\n",
    "c = np.concatenate((a, b), axis=0)\n",
    "print(f'{c.shape=}')\n",
    "d = np.array([])\n",
    "print(f'{d.shape=}')\n",
    "# e = np.concatenate((c, d), axis=0)\n",
    "# print(f'{e.shape=}')\n",
    "# f = np.append(d, a, axis=0)\n",
    "# print(f'{f.shape=}')\n",
    "g = np.vstack((a, b))\n",
    "print(f'{g.shape=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3])\n",
    "print(f'[1]  {id(a)=}')\n",
    "b = 1.0\n",
    "a = a * b\n",
    "print(f'[2]  {id(a)=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2]\n",
    "print(a[len(a)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {}\n",
    "print(len(a))\n",
    "b = {'1':1, '2':[2,3,4]}\n",
    "print(b)\n",
    "a.update(b)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision as tv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv.models.MobileNetV2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self,inp_c,out_c):\n",
    "        super(Head,self).__init__()\n",
    "        self.conv2d=nn.Conv2d(inp_c,out_c,3,2,padding=1,bias=False)\n",
    "        self.bn=nn.BatchNorm2d(out_c)\n",
    "        self.relu6=nn.ReLU6(inplace=True)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=self.conv2d(x)\n",
    "        x=self.bn(x)\n",
    "        out=self.relu6(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvertResidual(nn.Module):\n",
    "    def __init__(self,inp_c,out_c,stride,expand):\n",
    "        super(InvertResidual,self).__init__()\n",
    "        self.stride=stride\n",
    "        out_ce=out_c*expand\n",
    "        self.conv1_1=nn.Conv2d(inp_c,out_ce,1,bias=False)\n",
    "        self.conv1_2=nn.Conv2d(out_ce,out_c,1,bias=False)\n",
    "        self.bn1=nn.BatchNorm2d(out_ce)\n",
    "        self.bn2=nn.BatchNorm2d(out_c)\n",
    "        self.deepwide=nn.Conv2d(out_ce,out_ce,3,stride,padding=1,groups=out_c)\n",
    "        self.relu6=nn.ReLU6(inplace=True)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride == 1 and inp_c != out_c:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(inp_c,out_c,1,bias=False),\n",
    "                nn.BatchNorm2d(out_c))\n",
    "            \n",
    "        \n",
    "    def forward(self,x):\n",
    "        ori_x=x\n",
    "        x=self.conv1_1(x)\n",
    "        x=self.bn1(x)\n",
    "        x=self.relu6(x)\n",
    "        x=self.deepwide(x)\n",
    "        x=self.bn1(x)\n",
    "        x=self.relu6(x)\n",
    "        x=self.conv1_2(x)\n",
    "        y=self.bn2(x)\n",
    "        out=y + self.shortcut(ori_x) if self.stride==1 else y\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobileNetv2(nn.Module):\n",
    "    def __init__(self,width_mult=1,num_classes=100):\n",
    "        super(MobileNetv2,self).__init__()\n",
    "        block = InvertResidual\n",
    "        input_channel = 32\n",
    "        interverted_residual_setting = [\n",
    "            # t, c, n, s\n",
    "            [1, 16, 1, 1],\n",
    "            [6, 24, 2, 2],\n",
    "            [6, 32, 3, 2],\n",
    "            [6, 64, 4, 2],\n",
    "            [6, 96, 3, 1],\n",
    "            [6, 160, 3, 2],\n",
    "            [6, 320, 1, 1]]\n",
    "        input_channel=int(input_channel * width_mult)\n",
    "        head_layer=Head(3,input_channel)\n",
    "        self.layers=[head_layer]\n",
    "        for t, c, n, s in interverted_residual_setting:\n",
    "            stride = s\n",
    "            output_channel = int(c * width_mult)\n",
    "            for i in range(n):\n",
    "                if i==0:\n",
    "                    self.layers.append(block(input_channel,output_channel,stride,t))\n",
    "                else:\n",
    "                    self.layers.append(block(input_channel,output_channel,1,t))\n",
    "                input_channel=output_channel\n",
    "                \n",
    "        self.layers = nn.Sequential(*self.layers)\n",
    " \n",
    "        self.conv_end = nn.Conv2d(320,1280, kernel_size=1, stride=1,padding=0, bias=False)\n",
    "        self.bn_end = nn.BatchNorm2d(1280)\n",
    "        self.relu=nn.ReLU6(inplace=True)\n",
    "        self.AdaptiveAvgPool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.linear = nn.Linear(1280, num_classes)\n",
    "    def forward(self,x):\n",
    "        x=self.layers(x)\n",
    "        x=self.conv_end(x)\n",
    "        x=self.bn_end(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.AdaptiveAvgPool(x)\n",
    "        x= x.view(x.size(0), -1)\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "    test_input=torch.rand(1, 3, 480, 640)\n",
    "    print(test_input.size())\n",
    "    model= MobileNetv2()\n",
    "    out=model(test_input )\n",
    "    print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "for i in range(0, 101, 2):\n",
    "    time.sleep(0.1)  #线程推迟指定时间运行，0.1秒代表休眠100毫秒\n",
    "    num = i // 2\n",
    "    if i == 100:\n",
    "        process = \"\\r[%3s%%]: |%-50s|\\n\" % (i, '|' * num)\n",
    "    else:\n",
    "        process = \"\\r[%3s%%]: |%-50s|\" % (i, '|' * num)\n",
    "    print(process, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, time\n",
    "print(\"正在下载......\")\n",
    "for i in range(11):#通过for循环输出进度条效果\n",
    "    if i != 10:\n",
    "        sys.stdout.write(\"==\")\n",
    "    else:\n",
    "        sys.stdout.write(\"== \" + str(i*10)+\"%/100%\")\n",
    "        sys.stdout.flush()\n",
    "    time.sleep(0.5)#sleep用来控制输出时间\n",
    "print(\" \" + \"下载完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "for i in tqdm(range(20)):#也可改写为for i in trange(20):\n",
    "\tsleep(0.5)#sleep用来控制输出时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from progressbar import *\n",
    "progress = ProgressBar()\n",
    "for i in progress(range(1000)):\n",
    "\ttime.sleep(0.01)#sleep用来控制输出时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    time.sleep(1)\n",
    "    print(f'\\r**== {i} ==**', end='', flush=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.linspace(0, 9, 10).reshape((2,5))\n",
    "for i in range(10):\n",
    "    time.sleep(1)\n",
    "    print(f'\\r**== {list(a+i)} ==**', end='', flush=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "\n",
    "data = [\n",
    "    [\"小明\",\"01\",\"男\"],\n",
    "    [\"小红\",\"02\",\"女\"],\n",
    "    [\"小黄\",\"03\",\"男\"]\n",
    "]\n",
    "\n",
    "import numpy as np\n",
    "a = np.linspace(0, 9, 10).reshape((2,5))\n",
    "for i in range(5):\n",
    "    time.sleep(1)\n",
    "    table=PrettyTable([\"姓名\",\"学号\",\"性别\"])\n",
    "    table.add_row(data[i%3])\n",
    "    # print(f'\\r{table.get_string()[:-1]}', end='', flush=True)\n",
    "    sys.stdout.write(f'{table.get_string()[:-1]}')\n",
    "    # table.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "a = 0\n",
    "for i in range(5):\n",
    "    statement = \"\"\"\n",
    "    Line {}\n",
    "    Line {}\n",
    "    Line {}\n",
    "    Value = {}\n",
    "    \"\"\".format(random.random(), random.random(), random.random(), a)\n",
    "    print(statement, end='\\r')\n",
    "    time.sleep(1)\n",
    "    a += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python3\n",
    "\n",
    "import curses\n",
    "from time import sleep\n",
    "from random import random\n",
    "\n",
    "statement = \"\"\"\n",
    "Line {}\n",
    "Line {}\n",
    "Line {}\n",
    "Value = {}\"\"\"\n",
    "\n",
    "screen = curses.initscr()\n",
    "n = 0\n",
    "\n",
    "while n < 5:\n",
    "    screen.clear()\n",
    "    screen.addstr(0, 0, statement.format(random(), random(), random(), n))\n",
    "    screen.refresh()\n",
    "    n += 1\n",
    "    sleep(0.5)\n",
    "\n",
    "curses.endwin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 好用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 好用\n",
    "\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "from easydl import clear_output\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "\n",
    "data = [\n",
    "    [\"小明\",\"01\",\"男\"],\n",
    "    [\"小红\",\"02\",\"女\"],\n",
    "    [\"小黄\",\"03\",\"男\"],\n",
    "    [\"小黄\",\"04\",\"男\"],\n",
    "    [\"小黄\",\"05\",\"男\"],\n",
    "    [\"小黄\",\"06\",\"男\"]\n",
    "]\n",
    "\n",
    "\n",
    "# for i in range(3):\n",
    "#     table=PrettyTable([\"姓名\",\"学号\",\"性别\"])\n",
    "#     table.add_row(data[i%3])\n",
    "\n",
    "#     os.system('clear')\n",
    "#     clear_output()\n",
    "#     sys.stdout.write(\"\\r{0}\".format(table.get_string()))\n",
    "#     sys.stdout.flush() \n",
    "#     time.sleep(1)\n",
    "\n",
    "table=PrettyTable([\"姓名\",\"学号\",\"性别\"])\n",
    "table.add_row(data[0])\n",
    "table.add_row(data[1])\n",
    "table.add_row(data[2])\n",
    "table.add_row(data[3])\n",
    "table.add_row(data[4])\n",
    "table.add_row(data[5])\n",
    "print(f'{table.get_string()}  {len(table.rows)}  {type(table.rows)}')\n",
    "# table.del_row(-1)\n",
    "# print(f'[1]  {table.get_string()}  {len(table.rows)}  {type(table.rows)}')\n",
    "# table.del_row(0)\n",
    "# print(f'[2]  {table.get_string()}  {len(table.rows)}  {type(table.rows)}')\n",
    "# table.clear_rows()\n",
    "# print(f'[3]  {table.get_string()}  {len(table.rows)}  {type(table.rows)}')\n",
    "keep = 20\n",
    "table = table[-keep:]\n",
    "print(f'[3]  {table.get_string()}  {len(table.rows)}  {type(table.rows)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "import logging\n",
    "import progressbar\n",
    " \n",
    "# progressbar.streams.wrap_stderr()\n",
    "# progressbar.StreamWrapper()\n",
    "progressbar.utils.StreamWrapper()\n",
    "logging.basicConfig()\n",
    " \n",
    "for i in progressbar.progressbar(range(10)):\n",
    "    logging.error('Got %d', i)\n",
    "    time.sleep(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar = progressbar.ProgressBar(redirect_stdout=True)\n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "    print('Some text', i)\n",
    "\n",
    "    time.sleep(0.1)\n",
    "\n",
    "    bar.update((i+1)*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "for i in tqdm(range(20), ascii=True,desc=\"1st loop\"):\n",
    "  for j in tqdm(range(10), ascii=True,desc=\"2nd loop\"):\n",
    "    time.sleep(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tqdm(total=100) as pbar:\n",
    "    for i in range(10):\n",
    "        time.sleep(0.1)\n",
    "        pbar.update(10)\n",
    "\n",
    "'''method 2'''\n",
    "pbar = tqdm(total=100)\n",
    "for i in range(10):\n",
    "    time.sleep(0.1)\n",
    "    pbar.update(10)\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb9a28ebe90e4252a321ca1455a37859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "demo：:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from tqdm import tqdm_notebook\n",
    "import time\n",
    "from tqdm.notebook import tqdm as tqdm_notebook\n",
    "\n",
    "for i in tqdm_notebook(range(100),desc='demo：'):\n",
    "    time.sleep(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 好"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "refs:\n",
    "\n",
    "https://www.cnblogs.com/softlin/p/13339766.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "进度条默认格式为： {l_bar}{bar}{r_bar}\n",
    "\n",
    "进度条分为三部分： 中间的图形(bar)，图形左边(l_bar)、图形右边(r_bar)\n",
    "\n",
    "l_bar： {desc}: {percentage:3.0f}%|\n",
    "\n",
    "bar: 进度条\n",
    "\n",
    "r_bar: |{n_fmt}/{total_fmt}[{elapsed}<{remaining},{rate_fmt}{postfix}]\n",
    "\n",
    "100%|█████████████████| 3/3 [00:03<00:00, 1.00s/it]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 5: 100%||██████████████████████| 5/5 [ 2.01s/it, loss= 0.227 |00:10<00:00]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from random import random\n",
    "\n",
    "data =np.linspace(0, 9, 10)\n",
    "data_loader = DataLoader(data, batch_size=2, num_workers=0, shuffle=False)\n",
    "\n",
    "iterator = tqdm(\n",
    "    data_loader,\n",
    "    maxinterval=10,\n",
    "    mininterval=2, \n",
    "    ncols=80,\n",
    "    bar_format='{l_bar}|{bar}| {n_fmt}/{total_fmt} [{rate_fmt}{postfix}|{elapsed}<{remaining}]',\n",
    "    nrows=10,smoothing=0.1)\n",
    "epoch =0\n",
    "for d in iterator:\n",
    "    time.sleep(2)\n",
    "    epoch +=1\n",
    "    # print(d)\n",
    "    iterator.set_description('epoch %d' %epoch)\n",
    "    iterator.set_postfix_str('loss={:^7.3f}'.format(random()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:console logging redirected to `tqdm.write()`\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "console logging redirected to `tqdm.write()`\n",
      "console logging redirected to `tqdm.write()`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:console logging redirected to `tqdm.write()`\n",
      " 22%|██▏       | 2/9 [00:01<00:03,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "console logging redirected to `tqdm.write()`\n",
      "console logging redirected to `tqdm.write()`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:console logging redirected to `tqdm.write()`\n",
      " 44%|████▍     | 4/9 [00:02<00:02,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "console logging redirected to `tqdm.write()`\n",
      "console logging redirected to `tqdm.write()`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:console logging redirected to `tqdm.write()`\n",
      " 67%|██████▋   | 6/9 [00:03<00:01,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "console logging redirected to `tqdm.write()`\n",
      "console logging redirected to `tqdm.write()`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:console logging redirected to `tqdm.write()`\n",
      " 89%|████████▉ | 8/9 [00:04<00:00,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "console logging redirected to `tqdm.write()`\n",
      "console logging redirected to `tqdm.write()`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:04<00:00,  1.97it/s]\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from tqdm import trange\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from tqdm.contrib.logging import logging_redirect_tqdm\n",
    "import time\n",
    "\n",
    "LOG = logging.getLogger(__name__)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    with logging_redirect_tqdm():\n",
    "        for i in trange(9):\n",
    "            if i%2 == 0:\n",
    "                LOG.info(\"console logging redirected to `tqdm.write()`\")\n",
    "            time.sleep(0.5)\n",
    "    # logging restored\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'a': 1, 'b': 2, 'c': 3, 'd': 4}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {'a':1, 'b':2}\n",
    "list(a.keys())\n",
    "list(a.values())\n",
    "b = {'c':3, 'd':4}\n",
    "a.update(b)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "b=[4,5,6]\n",
    "a.extend(b)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1615935208.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [1]\u001b[0;36m\u001b[0m\n\u001b[0;31m    print([x for x in xyz if x in a else 'inf'])\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "a = [2,3,4,5,6,7,8,9,0]\n",
    "xyz = [0,12,4,6,242,7,9]\n",
    "print([x for x in xyz if x in a else 'inf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('train')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d740c7646e63427e6191f8164d347786ef6ce3d268dc00d8555a471847f63fe7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
